{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_curve, roc_auc_score\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-09T10:09:12.265052Z","iopub.execute_input":"2023-04-09T10:09:12.266218Z","iopub.status.idle":"2023-04-09T10:09:13.313770Z","shell.execute_reply.started":"2023-04-09T10:09:12.266157Z","shell.execute_reply":"2023-04-09T10:09:13.312604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Dataset","metadata":{}},{"cell_type":"code","source":"X_train=pd.read_csv(\"/kaggle/input/hit-prediction-processed-data/Hit Prediction/X_train_selected.csv\")\nX_test=pd.read_csv(\"/kaggle/input/hit-prediction-processed-data/Hit Prediction/X_test_selected.csv\")\ny_train=np.load(\"/kaggle/input/hit-prediction-processed-data/Hit Prediction/y_train.npy\")\ny_test=np.load(\"/kaggle/input/hit-prediction-processed-data/Hit Prediction/y_test.npy\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T10:10:41.391707Z","iopub.execute_input":"2023-04-09T10:10:41.392309Z","iopub.status.idle":"2023-04-09T10:10:41.628996Z","shell.execute_reply.started":"2023-04-09T10:10:41.392246Z","shell.execute_reply":"2023-04-09T10:10:41.627790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fitting Best Estimators (Logistic, SVM, DT, RF, KNN, Naive Bayes)","metadata":{}},{"cell_type":"code","source":"lr = LogisticRegression(C=0.1, max_iter=10000, random_state=42)\nlr.fit(X_train, y_train)\n\nknn = KNeighborsClassifier(algorithm='ball_tree',n_neighbors=19,p=1,weights='distance')\nknn.fit(X_train, y_train)\n\nnb = GaussianNB(priors=None, var_smoothing=1e-09)\nnb.fit(X_train, y_train)\n\ndt = DecisionTreeClassifier(random_state=42,ccp_alpha=0.001)\ndt.fit(X_train, y_train)\n\nrf = RandomForestClassifier(max_depth=20, max_features='log2', n_estimators=300, oob_score=True, ccp_alpha=0.0004)\nrf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T10:17:07.236854Z","iopub.execute_input":"2023-04-09T10:17:07.238490Z","iopub.status.idle":"2023-04-09T10:18:41.508734Z","shell.execute_reply.started":"2023-04-09T10:17:07.238437Z","shell.execute_reply":"2023-04-09T10:18:41.507471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm = SVC(C=1.5, class_weight='balanced', gamma='scale', kernel='rbf',probability=True)\nsvm.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T10:21:38.987402Z","iopub.execute_input":"2023-04-09T10:21:38.987888Z","iopub.status.idle":"2023-04-09T10:25:56.189883Z","shell.execute_reply.started":"2023-04-09T10:21:38.987847Z","shell.execute_reply":"2023-04-09T10:25:56.188572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict Class Probabilities and Estimate TPR, FPR and AUC","metadata":{}},{"cell_type":"code","source":"# Predict the class probabilities for the validation set for each model\nlr_prob = lr.predict_proba(X_test)[:, 1]\nknn_prob = knn.predict_proba(X_test)[:, 1]\nnb_prob = nb.predict_proba(X_test)[:, 1]\nsvm_prob = svm.predict_proba(X_test)[:, 1]\ndt_prob = dt.predict_proba(X_test)[:, 1]\nrf_prob = rf.predict_proba(X_test)[:, 1]\n\n# Compute the FPR, TPR, and AUC for each model\nlr_fpr, lr_tpr, _ = roc_curve(y_test, lr_prob)\nlr_auc = roc_auc_score(y_test, lr_prob)\n\nknn_fpr, knn_tpr, _ = roc_curve(y_test, knn_prob)\nknn_auc = roc_auc_score(y_test, knn_prob)\n\nnb_fpr, nb_tpr, _ = roc_curve(y_test, nb_prob)\nnb_auc = roc_auc_score(y_test, nb_prob)\n\nsvm_fpr, svm_tpr, _ = roc_curve(y_test, svm_prob)\nsvm_auc = roc_auc_score(y_test, svm_prob)\n\ndt_fpr, dt_tpr, _ = roc_curve(y_test, dt_prob)\ndt_auc = roc_auc_score(y_test, dt_prob)\n\nrf_fpr, rf_tpr, _ = roc_curve(y_test, rf_prob)\nrf_auc = roc_auc_score(y_test, rf_prob)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T10:26:04.618594Z","iopub.execute_input":"2023-04-09T10:26:04.619105Z","iopub.status.idle":"2023-04-09T10:26:18.509001Z","shell.execute_reply.started":"2023-04-09T10:26:04.619057Z","shell.execute_reply":"2023-04-09T10:26:18.507620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot ROC graph and corresponding AUC","metadata":{}},{"cell_type":"code","source":"# Plot the ROC curves for each model\nplt.plot(lr_fpr, lr_tpr, label=f'Logistic Regression (AUC = {lr_auc:.2f})')\nplt.plot(knn_fpr, knn_tpr, label=f'KNN (AUC = {knn_auc:.2f})')\nplt.plot(nb_fpr, nb_tpr, label=f'Naive Bayes (AUC = {nb_auc:.2f})')\nplt.plot(svm_fpr, svm_tpr, label=f'SVM (AUC = {svm_auc:.2f})')\nplt.plot(dt_fpr, dt_tpr, label=f'Decision Tree (AUC = {dt_auc:.2f})')\nplt.plot(rf_fpr, rf_tpr, label=f'Random Forest (AUC = {rf_auc:.2f})')\n\n# Set the title and axis labels for the plot\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\n\n# Add a legend to the plot\nplt.legend()\n\n# Highlight the ROC curve for the best model\nbest_auc = max(lr_auc, knn_auc, nb_auc, svm_auc, dt_auc, rf_auc)\n\nif best_auc == lr_auc:\n    plt.plot(lr_fpr, lr_tpr, linewidth=2, linestyle='--', color='green')\nelif best_auc == knn_auc:\n    plt.plot(knn_fpr, knn_tpr, linewidth=2, linestyle='--', color='green')\nelif best_auc == nb_auc:\n    plt.plot(nb_fpr, nb_tpr, linewidth=2, linestyle='--', color='green')\nelif best_auc == svm_auc:\n    plt.plot(svm_fpr, svm_tpr, linewidth=2, linestyle='--', color='green')\nelif best_auc == dt_auc:\n    plt.plot(dt_fpr, dt_tpr, linewidth=2, linestyle='--', color='green')\nelif best_auc == rf_auc:\n    plt.plot(rf_fpr, rf_tpr, linewidth=2, linestyle='--', color='green')\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-09T10:26:52.850603Z","iopub.execute_input":"2023-04-09T10:26:52.851075Z","iopub.status.idle":"2023-04-09T10:26:53.240110Z","shell.execute_reply.started":"2023-04-09T10:26:52.851038Z","shell.execute_reply":"2023-04-09T10:26:53.239025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference \n> ### Support Vector Machine and Random Forest perform equally well and better than the rest of the models with an AUC of 0.85. They are good in discriminating the True Positives and False Positives. ","metadata":{}}]}